# Example environment variables for the Garage Grown Gear scraper
# Copy this file to .env and fill in your actual values
# 
# Setup Instructions:
# 1. Copy this file: cp .env.example .env
# 2. Follow docs/GOOGLE_SHEETS_SETUP.md to get credentials
# 3. Run: python setup_config.py to validate your setup

# ============================================================================
# GOOGLE SHEETS CONFIGURATION (REQUIRED)
# ============================================================================

# Your Google Sheets spreadsheet ID (44 characters)
# Get this from the URL: https://docs.google.com/spreadsheets/d/SPREADSHEET_ID/edit
# Example: 1BxiMVs0XRA5nFMdKvBdBZjgmUUqptlbs74OgvE2upms
SPREADSHEET_ID=your_google_sheets_id_here

# Name of the sheet tab to write data to
SHEET_NAME=Product_Data

# Path to your Google Sheets API credentials JSON file
# Download from Google Cloud Console > APIs & Services > Credentials
CREDENTIALS_FILE=service_account.json

# ============================================================================
# SCRAPER CONFIGURATION (OPTIONAL)
# ============================================================================

# Target URL to scrape (usually don't need to change this)
BASE_URL=https://www.garagegrowngear.com/collections/sale-1

# Maximum number of retry attempts for failed requests (0-10)
MAX_RETRIES=3

# Initial delay between retries in seconds (0-60)
RETRY_DELAY=1.0

# HTTP request timeout in seconds (1-300)
REQUEST_TIMEOUT=30

# Enable stealth mode to avoid detection (true/false)
USE_STEALTH_MODE=true

# Delay between consecutive requests in seconds (0-10)
# Higher values are more respectful but slower
DELAY_BETWEEN_REQUESTS=1.0

# ============================================================================
# LOGGING CONFIGURATION (OPTIONAL)
# ============================================================================

# Logging level: DEBUG, INFO, WARNING, ERROR, CRITICAL
# DEBUG: Most verbose, INFO: Normal, ERROR: Errors only
LOG_LEVEL=INFO

# Whether to write logs to a file (true/false)
LOG_TO_FILE=false

# Path for log file (only used if LOG_TO_FILE=true)
LOG_FILE_PATH=scraper.log

# ============================================================================
# NOTIFICATION CONFIGURATION (OPTIONAL)
# ============================================================================

# Enable notification system (true/false)
ENABLE_NOTIFICATIONS=false

# Webhook URL for notifications (Slack, Discord, etc.)
# Example: https://hooks.slack.com/services/YOUR/WEBHOOK/URL
WEBHOOK_URL=

# Enable email notifications (future feature, not implemented yet)
EMAIL_NOTIFICATIONS=false

# Percentage threshold for significant price drops (0-100)
# Products with price drops >= this percentage will be flagged
PRICE_DROP_THRESHOLD=20.0

# ============================================================================
# EXAMPLE CONFIGURATIONS
# ============================================================================

# For faster scraping (use with caution):
# DELAY_BETWEEN_REQUESTS=0.5
# REQUEST_TIMEOUT=15
# MAX_RETRIES=2

# For debugging:
# LOG_LEVEL=DEBUG
# LOG_TO_FILE=true

# For production with notifications:
# ENABLE_NOTIFICATIONS=true
# WEBHOOK_URL=https://hooks.slack.com/services/YOUR/WEBHOOK/URL
# PRICE_DROP_THRESHOLD=15.0