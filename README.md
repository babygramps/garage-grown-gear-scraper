# Garage Grown Gear Scraper

A robust, automated web scraping bot that monitors the [Garage Grown Gear sale page](https://www.garagegrowngear.com/collections/sale-1) and saves product data to Google Sheets. Features include change detection, price monitoring, and automated GitHub Actions execution.

## âœ¨ Features

- ðŸ•·ï¸ **Robust Web Scraping**: Uses Scrapling for reliable data extraction with stealth mode
- ðŸ“Š **Google Sheets Integration**: Automatically saves data with proper formatting
- ðŸ”„ **Automated Execution**: Runs on GitHub Actions every 6 hours
- ðŸ“ˆ **Change Detection**: Identifies new products and significant price changes
- ðŸ›¡ï¸ **Error Handling**: Comprehensive retry logic and graceful error recovery
- ðŸ“ **Detailed Logging**: Structured logging with configurable levels
- âš™ï¸ **Flexible Configuration**: Environment-based configuration with validation
- ðŸ§ª **Comprehensive Testing**: Full test suite with unit and integration tests

## ðŸš€ Quick Start

### Prerequisites

- Python 3.8 or higher
- Google account with access to Google Sheets
- GitHub account (for automated execution)

### 1. Installation

```bash
# Clone the repository
git clone https://github.com/yourusername/garage-grown-gear-scraper.git
cd garage-grown-gear-scraper

# Install dependencies
pip install -r requirements.txt
```

### 2. Configuration Setup

Run the automated setup script:

```bash
python setup_config.py
```

This will:
- âœ… Check Python version and dependencies
- âœ… Create `.env` file from template
- âœ… Validate your configuration
- âœ… Provide setup instructions for missing components

### 3. Google Sheets Setup

Follow the detailed guide: [Google Sheets Setup](docs/GOOGLE_SHEETS_SETUP.md)

**Quick version:**
1. Create a Google Cloud project
2. Enable Google Sheets API
3. Create a service account and download JSON credentials
4. Create a Google Sheet and share it with your service account
5. Set `SPREADSHEET_ID` in your `.env` file

### 4. Run the Scraper

```bash
# Run once
python main.py

# Run with debug logging
LOG_LEVEL=DEBUG python main.py
```

## ðŸ“ Project Structure

```
garage-grown-gear-scraper/
â”œâ”€â”€ ðŸ“‚ scraper/                 # Web scraping modules
â”‚   â””â”€â”€ garage_grown_gear_scraper.py
â”œâ”€â”€ ðŸ“‚ data_processing/         # Data validation and processing
â”‚   â”œâ”€â”€ product_data_processor.py
â”‚   â”œâ”€â”€ change_detector.py
â”‚   â””â”€â”€ validators.py
â”œâ”€â”€ ðŸ“‚ sheets_integration/      # Google Sheets API integration
â”‚   â””â”€â”€ sheets_client.py
â”œâ”€â”€ ðŸ“‚ error_handling/          # Error handling and logging
â”‚   â”œâ”€â”€ exceptions.py
â”‚   â”œâ”€â”€ logging_config.py
â”‚   â”œâ”€â”€ monitoring.py
â”‚   â””â”€â”€ retry_handler.py
â”œâ”€â”€ ðŸ“‚ tests/                   # Comprehensive test suite
â”œâ”€â”€ ðŸ“‚ docs/                    # Documentation
â”‚   â”œâ”€â”€ GOOGLE_SHEETS_SETUP.md
â”‚   â”œâ”€â”€ CONFIGURATION.md
â”‚   â””â”€â”€ CHANGE_DETECTION.md
â”œâ”€â”€ ðŸ“‚ .github/workflows/       # GitHub Actions automation
â”‚   â””â”€â”€ scraper.yml
â”œâ”€â”€ ðŸ“‚ examples/                # Usage examples
â”œâ”€â”€ config.py                   # Configuration management
â”œâ”€â”€ main.py                     # Main entry point
â”œâ”€â”€ setup_config.py             # Configuration setup script
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ .env.example               # Environment variables template
â””â”€â”€ README.md                  # This file
```

## âš™ï¸ Configuration

### Environment Variables

Copy `.env.example` to `.env` and customize:

```bash
cp .env.example .env
```

**Required:**
- `SPREADSHEET_ID`: Your Google Sheets spreadsheet ID
- `CREDENTIALS_FILE`: Path to Google Sheets API credentials

**Optional (with defaults):**
- `LOG_LEVEL`: Logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
- `MAX_RETRIES`: Maximum retry attempts (default: 3)
- `DELAY_BETWEEN_REQUESTS`: Delay between requests in seconds (default: 1.0)

See [Configuration Reference](docs/CONFIGURATION.md) for all options.

### Configuration Validation

Validate your setup:

```bash
python setup_config.py
```

## ðŸ¤– GitHub Actions Automation

### Setup

1. Fork this repository
2. Add GitHub Secrets:
   - `GOOGLE_SHEETS_CREDENTIALS`: Base64-encoded credentials JSON
   - `SPREADSHEET_ID`: Your spreadsheet ID

### Workflow

The scraper runs automatically:
- **Schedule**: Every 6 hours
- **Manual**: Via GitHub Actions "Run workflow" button
- **Logs**: Available in GitHub Actions tab

## ðŸ“Š Data Output

The scraper creates a Google Sheet with these columns:

| Column | Description | Example |
|--------|-------------|---------|
| Timestamp | When data was collected | 2024-01-15 10:30:00 |
| Product Name | Full product name | Patagonia Better Sweater Jacket |
| Brand | Product brand | Patagonia |
| Current Price | Sale price | $89.99 |
| Original Price | Regular price | $149.99 |
| Discount % | Percentage discount | 40% |
| Availability | Stock status | Available / Sold out |
| Rating | Product rating | 4.5 |
| Reviews | Number of reviews | 123 |
| Product URL | Link to product page | https://... |

## ðŸ” Change Detection

The scraper automatically detects:
- ðŸ†• **New products** added to sale
- ðŸ’° **Significant price drops** (configurable threshold)
- ðŸ“¦ **Stock status changes** (available â†’ sold out)
- ðŸ·ï¸ **New sale labels** and promotions

See [Change Detection Guide](docs/CHANGE_DETECTION.md) for details.

## ðŸ§ª Testing

Run the test suite:

```bash
# Run all tests
python -m pytest

# Run with coverage
python -m pytest --cov=. --cov-report=html

# Run specific test file
python -m pytest tests/test_scraper.py

# Run integration tests (requires valid config)
python -m pytest tests/test_integration.py
```

## ðŸ“š Documentation

- ðŸ“– [Google Sheets Setup Guide](docs/GOOGLE_SHEETS_SETUP.md)
- âš™ï¸ [Configuration Reference](docs/CONFIGURATION.md)
- ðŸ” [Change Detection Guide](docs/CHANGE_DETECTION.md)
- ðŸ§ª [Testing Guide](tests/README.md)

## ðŸ› ï¸ Development

### Local Development

```bash
# Install development dependencies
pip install -r requirements.txt

# Run with debug logging
LOG_LEVEL=DEBUG python main.py

# Run tests
python -m pytest

# Validate configuration
python setup_config.py
```

### Adding New Features

1. Follow the existing code structure
2. Add comprehensive tests
3. Update documentation
4. Validate with `python setup_config.py`

## ðŸ› Troubleshooting

### Common Issues

**"SPREADSHEET_ID is required but not provided"**
```bash
# Set in .env file
echo "SPREADSHEET_ID=your_spreadsheet_id" >> .env
```

**"Credentials file not found"**
```bash
# Ensure service_account.json exists
ls -la service_account.json
```

**"The caller does not have permission"**
- Share your Google Sheet with the service account email
- Grant "Editor" permissions

**Rate limiting or blocking**
- Increase `DELAY_BETWEEN_REQUESTS` in `.env`
- Enable `USE_STEALTH_MODE=true`

### Getting Help

1. Run `python setup_config.py` for configuration validation
2. Check logs for detailed error messages
3. Review the [troubleshooting guides](docs/)
4. Open an issue with error details and configuration (remove sensitive data)

## ðŸ“ˆ Performance

### Typical Performance

- **Pages per minute**: ~10-15 (with 1s delays)
- **Products per run**: 50-200 (depends on sale inventory)
- **Memory usage**: <100MB
- **Execution time**: 2-5 minutes per run

### Optimization Tips

- Adjust `DELAY_BETWEEN_REQUESTS` for speed vs. politeness
- Use `LOG_LEVEL=WARNING` in production for better performance
- Enable `USE_STEALTH_MODE` to avoid detection

## ðŸ”’ Security & Ethics

### Web Scraping Ethics

- âœ… Respects robots.txt
- âœ… Uses reasonable delays between requests
- âœ… Only scrapes publicly available data
- âœ… Implements proper error handling
- âœ… Uses stealth mode to avoid server overload

### Security Best Practices

- ðŸ” Never commit credentials to version control
- ðŸ” Use GitHub Secrets for sensitive data
- ðŸ” Regularly rotate API keys
- ðŸ” Follow principle of least privilege

## ðŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ðŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ðŸ“ž Support

- ðŸ“– Check the [documentation](docs/)
- ðŸ› Report bugs via [GitHub Issues](https://github.com/yourusername/garage-grown-gear-scraper/issues)
- ðŸ’¬ Ask questions in [Discussions](https://github.com/yourusername/garage-grown-gear-scraper/discussions)

---

**Disclaimer**: This tool is for educational and personal use only. Please respect the website's terms of service and use responsibly.